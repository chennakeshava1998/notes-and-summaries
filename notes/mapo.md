### ![MAPO Liang et al](https://arxiv.org/pdf/1807.02322.pdf)

#### Key Points:
1. Applicable to deterministic environments with discrete actions (why?)

#### Doubts:
1. How is this method different from prioritised experiance replay in DQNs?
2. Have DQNs been used for program synthesis?
3. How is this weakly supervised training?